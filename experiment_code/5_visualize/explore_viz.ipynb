{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/kn2347/.conda/envs/medsam/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import RandomSampler\n",
    "import random\n",
    "import scipy\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import wandb\n",
    "import re\n",
    "from adjustText import adjust_text\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import scipy\n",
    "import statannot\n",
    "import argparse\n",
    "import sys\n",
    "#print(glob('../../*'))\n",
    "sys.path.append('../../modified_medsam_repo')\n",
    "from MedSAM_HCP.utils_hcp import *\n",
    "from MedSAM_HCP.dataset import MRIDataset, MRIDatasetForPooled, MRIDataset_Imgs, load_datasets, LabelConverter\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_type, model_path, num_classes):\n",
    "    result = torch.load(model_path)\n",
    "    try:\n",
    "        if 'model' in result.keys():\n",
    "            splits = model_path.split('/')\n",
    "            new_path = os.path.join('/'.join(splits[:-1]), f'{splits[-1].split(\".pth\")[0]}_sam_readable.pth')\n",
    "            print(f'model path converted to sam readable format and saved to {new_path}')\n",
    "\n",
    "            result = result['model']\n",
    "\n",
    "            # now remove the \"module.\" prefix\n",
    "            result_dict = {}\n",
    "            for k,v in result.items():\n",
    "                key_splits = k.split('.')\n",
    "                assert key_splits[0] == 'module'\n",
    "                new_k = '.'.join(key_splits[1:])\n",
    "                result_dict[new_k] = v\n",
    "\n",
    "            torch.save(result_dict, new_path)\n",
    "            model_path = new_path\n",
    "\n",
    "    except (AttributeError):\n",
    "        # already in the correct format\n",
    "        print('model path in readable format already')\n",
    "\n",
    "    if model_type == 'multitask_unprompted':\n",
    "        model = build_sam_vit_b_multiclass(num_classes, checkpoint=model_path).to('cuda')\n",
    "    elif model_type == 'pooltask_yolov7_prompted':\n",
    "        model = build_sam_vit_b_multiclass(num_classes, checkpoint=model_path).to('cuda')\n",
    "    elif model_type == 'singletask_unet':\n",
    "        model = torch.load(model_path)\n",
    "    else:\n",
    "        # singletask model\n",
    "        model = build_sam_vit_b_multiclass(3, checkpoint=model_path).to('cuda')\n",
    "\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcp = pd.read_csv('/gpfs/home/kn2347/HCP_MedSAM_project/modified_medsam_repo/hcp_mapping_processed.csv')\n",
    "df_desired = pd.read_csv('/gpfs/home/kn2347/HCP_MedSAM_project/modified_medsam_repo/darts_name_class_mapping_processed.csv')\n",
    "label_converter = LabelConverter(df_hcp, df_desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcp = pd.read_csv('/gpfs/data/luilab/karthik/pediatric_seg_proj/path_df_unet.csv', dtype={'id': str})\n",
    "df_brats = pd.read_csv('/gpfs/data/luilab/karthik/pediatric_seg_proj/other_path_dfs/path_df_brats_unet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function preprocess_input at 0x15545ab54c10>, input_space='RGB', input_range=[0, 1], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path in readable format already\n"
     ]
    }
   ],
   "source": [
    "label = 1\n",
    "preprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')\n",
    "model_path = glob(f'/gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/unet_retrain_all_labels_9-9-24/training/{label}/*-best_model.pth')[0]\n",
    "model = load_model('singletask_unet', model_path, num_classes=1)\n",
    "dataset_hcp = MRIDataset_Imgs(df_hcp, label_id = label, bbox_shift=0, label_converter = label_converter, NUM_CLASSES=2, as_one_hot=True, pool_labels=False, preprocess_fn=preprocess_input)\n",
    "dataset_brats = MRIDataset_Imgs(df_brats, label_id = label, bbox_shift=0, label_converter = label_converter, NUM_CLASSES=2, as_one_hot=True, pool_labels=False, preprocess_fn=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2108061"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hcp[200][0].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_brats[128][0].numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['100206', '100307', '100408', ..., '994273', '995174', '996782'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hcp.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brats.iloc[128,2]\n",
    "df_hcp.iloc[128,2]\n",
    "\n",
    "for id in df_hcp.id.unique():\n",
    "    listo = []\n",
    "    for i in range(256):\n",
    "        npo = np.array(Image.open(f'/gpfs/data/cbi/hcp/hcp_ya/hcp_ya_slices_npy/dir_structure_for_yolov7/train/images/{id}_slice{i}.png'))\n",
    "        listo.append(npo.max())\n",
    "    print(f'{id}: {np.max(listo)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6399999999999997\n"
     ]
    }
   ],
   "source": [
    "npo = np.array(Image.open('/gpfs/data/luilab/karthik/MICCAI_BraTS2020_TrainingData/images/images001_slice128.png'))\n",
    "print(preprocess_input(npo).max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
