{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "join = os.path.join\n",
    "from tqdm import tqdm\n",
    "from skimage import transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "import monai\n",
    "import sys\n",
    "sys.path.append('./modified_medsam_repo')\n",
    "from segment_anything import sam_model_registry\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "import time\n",
    "from PIL import Image\n",
    "from MedSAM_HCP.dataset import MRIDataset_Imgs, load_datasets\n",
    "from MedSAM_HCP.MedSAM import MedSAM\n",
    "from MedSAM_HCP.build_sam import build_sam_vit_b_multiclass\n",
    "from MedSAM_HCP.utils_hcp import *\n",
    "from MedSAM_HCP.loss_funcs_hcp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do\n",
    "    srun -lN1 --mem=100G --gres=gpu:1 -c $SLURM_CPUS_ON_NODE -N 1 -n 1 -r $i bash -c \\\n",
    "    \"python /gpfs/home/kn2347/MedSAM/train_multi_gpus_modified_multiclass.py \\\n",
    "        --data_frame_path /gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/yolov7/path_df_pooled_labels_only_with_bbox_yolov7.csv \\\n",
    "        --df_desired_path /gpfs/home/kn2347/MedSAM/darts_name_class_mapping_processed.csv \\\n",
    "        -train_test_splits /gpfs/data/luilab/karthik/pediatric_seg_proj/train_val_test_split.pickle \\\n",
    "        -task_name MedSAM_finetune_final_round \\\n",
    "        --wandb_run_name pooled_labels_yolov7 \\\n",
    "        -checkpoint /gpfs/home/kn2347/MedSAM/medsam_vit_b.pth \\\n",
    "        -work_dir /gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/pool_model_rerun_8-26-23 \\\n",
    "        -label_id 1 \\\n",
    "        -batch_size 64 \\\n",
    "        -num_workers 4 \\\n",
    "        -num_epochs 30 \\\n",
    "        --lambda_dice 0 \\\n",
    "        -lr 1e-4 \\\n",
    "        -use_wandb True \\\n",
    "        -use_amp \\\n",
    "        --suppress_train_debug_imgs \\\n",
    "        --pool_labels \\\n",
    "        --world_size ${WORLD_SIZE} \\\n",
    "        --bucket_cap_mb 25 \\\n",
    "        --grad_acc_steps 1 \\\n",
    "        --node_rank ${i} \\\n",
    "        --init_method tcp://${MASTER_ADDR}:${MASTER_PORT}\" >> ./logs/log_for_${SLURM_JOB_ID}_node_${i}.log 2>&1 &\n",
    "done\n",
    "wait ## Wait for the tasks on nodes to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MRIDataset_Imgs(Dataset): \n",
    "    def __init__(self, data_frame, label_id=None, bbox_shift=0, label_converter=None, NUM_CLASSES = 256, as_one_hot = True, pool_labels = False, preprocess_fn=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.bbox_shift = bbox_shift\n",
    "        self.label_id = label_id\n",
    "        self.label_converter = label_converter\n",
    "        self.NUM_CLASSES = NUM_CLASSES\n",
    "        self.as_one_hot = as_one_hot\n",
    "        self.pool_labels = pool_labels\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "\n",
    "        if self.label_converter is None:\n",
    "            print('Initializing with no label converter, are you sure the labels are correct?')\n",
    "\n",
    "        #if self.pool_labels and self.label_converter is not None: actually, will already come compressed\n",
    "        #    self.data_frame['label_number'] = self.label_converter.hcp_to_compressed(self.data_frame['label_number'])\n",
    "        #print(f'number of images: {data_frame.shape[0]}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_frame.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image as npy (256x256x3)\n",
    "        img_path = self.data_frame.loc[index,'img_slice_path']\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        img_npy = np.array(img)\n",
    "\n",
    "        if self.preprocess_fn is not None:\n",
    "            img_npy = self.preprocess_fn(img_npy)\n",
    "            \n",
    "        img_npy = np.transpose(img_npy, axes = (2, 0, 1))\n",
    "\n",
    "\n",
    "\n",
    "        #img_npy = np.load(img_path)\n",
    "        \n",
    "        # load segmentation mask as npy\n",
    "        seg_path = self.data_frame.loc[index,'segmentation_slice_path']\n",
    "        seg_npy = np.load(seg_path) # (256, 256)\n",
    "\n",
    "        if self.label_converter is not None:\n",
    "            seg_npy = self.label_converter.hcp_to_compressed(seg_npy)\n",
    "\n",
    "        if self.label_id is not None:\n",
    "           seg_npy = (seg_npy == self.label_id)\n",
    "\n",
    "        # currently seg_npy is (H,W)\n",
    "        seg_tens = torch.LongTensor(seg_npy[None, :, :]) # B, H, W\n",
    "        seg_tens = torch.nn.functional.one_hot(seg_tens, num_classes=self.NUM_CLASSES) # B, H, W, C\n",
    "        \n",
    "        seg_tens = torch.permute(seg_tens, (0, 3, 1, 2)) # B, C, H, W\n",
    "        seg_tens = seg_tens[0] # exclude batch dimension -> C, H, W\n",
    "        # ignore 0th channel\n",
    "        seg_tens = seg_tens[1:,:,:]\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        if self.label_id is None: # use all classes\n",
    "            # currently seg_npy is (H,W)\n",
    "            seg_tens = torch.LongTensor(seg_npy[None, :, :]) # B, H, W\n",
    "            seg_tens = torch.nn.functional.one_hot(seg_tens, num_classes=self.NUM_CLASSES) # B, H, W, C\n",
    "            seg_tens = torch.permute(seg_tens, (0, 3, 1, 2)) # B, C, H, W\n",
    "            seg_tens = seg_tens[0] # exclude batch dimension -> C, H, W\n",
    "        '''\n",
    "\n",
    "        ido = self.data_frame.loc[index,'id']\n",
    "        sliceo = self.data_frame.loc[index,'slice']\n",
    "        img_slice_name = f'{ido}_{sliceo}'\n",
    "\n",
    "        return torch.tensor(img_npy).float(), seg_tens\n",
    "\n",
    "# code to load train, val, test datasets\n",
    "def load_datasets(path_df_path, train_test_splits_path, label_id, bbox_shift=0, \n",
    "                sample_n_slices = None, label_converter=None, NUM_CLASSES=256, \n",
    "                as_one_hot=True, pool_labels=False,\n",
    "                preprocess_fn = None):\n",
    "    # load dataframe of slice paths\n",
    "    path_df = pd.read_csv(path_df_path)\n",
    "\n",
    "    # load train val test ids\n",
    "    dicto = pickle.load(open(train_test_splits_path, 'rb'))\n",
    "    train_ids = dicto['train']\n",
    "    val_ids = dicto['val']\n",
    "    test_ids = dicto['test']\n",
    "\n",
    "    train_df = path_df[path_df['id'].isin(train_ids)].reset_index(drop=True)\n",
    "    val_df = path_df[path_df['id'].isin(val_ids)].reset_index(drop=True)\n",
    "    test_df = path_df[path_df['id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MRIDataset_Imgs(train_df, label_id, bbox_shift, label_converter = label_converter, NUM_CLASSES=NUM_CLASSES, as_one_hot=as_one_hot, pool_labels=pool_labels, preprocess_fn = preprocess_fn)\n",
    "    val_dataset = MRIDataset_Imgs(val_df, label_id, 0, label_converter = label_converter, NUM_CLASSES=NUM_CLASSES, as_one_hot=as_one_hot, pool_labels=pool_labels, preprocess_fn = preprocess_fn)\n",
    "    test_dataset = MRIDataset_Imgs(test_df, label_id, 0, label_converter = label_converter, NUM_CLASSES=NUM_CLASSES, as_one_hot=as_one_hot, pool_labels=pool_labels, preprocess_fn = preprocess_fn)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     dfo \u001b[38;5;241m=\u001b[39m dfo[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_slice_path\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation_slice_path\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dfo\n\u001b[0;32m---> 38\u001b[0m new_train \u001b[38;5;241m=\u001b[39m modify_df(\u001b[43mtrain_df\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m new_val \u001b[38;5;241m=\u001b[39m modify_df(val_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m new_test \u001b[38;5;241m=\u001b[39m modify_df(test_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "#path_df_path = '/gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/medsam/path_df_label1_only_with_bbox.csv'\n",
    "path_df_path = '/gpfs/data/luilab/karthik/pediatric_seg_proj/path_df.csv'\n",
    "train_test_splits_path = '/gpfs/data/luilab/karthik/pediatric_seg_proj/train_val_test_split.pickle'\n",
    "#train_dataset, val_dataset, test_dataset = load_datasets(path_df_path, train_test_splits_path, label_id = 2, bbox_shift=0, sample_n_slices = None)\n",
    "\n",
    "\n",
    "path_df = pd.read_csv(path_df_path)\n",
    "\n",
    "\n",
    "# load train val test ids\n",
    "dicto = pickle.load(open(train_test_splits_path, 'rb'))\n",
    "train_ids = dicto['train']\n",
    "val_ids = dicto['val']\n",
    "test_ids = dicto['test']\n",
    "\n",
    "#train_df = path_df[path_df['id'].isin(train_ids)].reset_index(drop=True)\n",
    "#val_df = path_df[path_df['id'].isin(val_ids)].reset_index(drop=True)\n",
    "#test_df = path_df[path_df['id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def modify_df(df, tr_type):\n",
    "    assert tr_type in ['train', 'val', 'test']\n",
    "    dfo = df\n",
    "    listo = []\n",
    "    seglisto = []\n",
    "    for i, r in df.iterrows():    \n",
    "        imgpath = os.path.join(f'/gpfs/data/cbi/hcp/hcp_ya/hcp_ya_slices_npy/dir_structure_for_yolov7/{tr_type}/images',\n",
    "                    f'{r.id}_slice{r.slice}.png')\n",
    "        segpath = os.path.join(f'/gpfs/data/cbi/hcp/hcp_ya/hcp_ya_slices_npy/segmentation_slices', f'{r.id}', f'seg_{r.slice}.npy')\n",
    "        listo.append(imgpath)\n",
    "        seglisto.append(segpath)\n",
    "\n",
    "    dfo['img_slice_path'] = listo\n",
    "    dfo['segmentation_slice_path'] = seglisto\n",
    "    dfo = dfo[['id', 'slice', 'img_slice_path', 'segmentation_slice_path']]\n",
    "    return dfo\n",
    "\n",
    "new_train = modify_df(train_df, 'train')\n",
    "new_val = modify_df(val_df, 'val')\n",
    "new_test = modify_df(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([new_train, new_val, new_test])\n",
    "all_df.to_csv('/gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/baseline_unet/all_labels_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv('/gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/baseline_unet/label1/train_df.csv')\n",
    "new_val.to_csv('/gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/baseline_unet/label1/val_df.csv')\n",
    "new_test.to_csv('/gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/baseline_unet/label1/test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "activation = 'sigmoid'\n",
    "batch_sz = 256\n",
    "label_id = 7\n",
    "lr = 1e-4 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hcp = pd.read_csv('/gpfs/home/kn2347/MedSAM/hcp_mapping_processed.csv')\n",
    "df_desired = pd.read_csv('/gpfs/home/kn2347/MedSAM/darts_name_class_mapping_processed.csv')\n",
    "label_converter = LabelConverter(df_hcp, df_desired)\n",
    "\n",
    "preprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')\n",
    "\n",
    "train, val, test = load_datasets('/gpfs/data/luilab/karthik/pediatric_seg_proj/per_class_isolated_df/baseline_unet/all_labels_df.csv',\n",
    "            '/gpfs/data/luilab/karthik/pediatric_seg_proj/train_val_test_split.pickle',\n",
    "            label_id = label_id, bbox_shift=0, \n",
    "                sample_n_slices = None, label_converter=label_converter, NUM_CLASSES=num_classes+1, \n",
    "                as_one_hot=True, pool_labels=False, preprocess_fn = preprocess_input,\n",
    "                dataset_type = MRIDataset_Imgs)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_sz, shuffle=False, num_workers=0)\n",
    "valid_loader = DataLoader(val, batch_size=batch_sz, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test, batch_size=batch_sz, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=num_classes,            # model output channels (number of classes in your dataset)\n",
    "    activation = activation\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = smp.utils.metrics.IoU(threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 256, 256])\n",
      "torch.Size([256, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "it = iter(train_loader)\n",
    "first = next(it)\n",
    "zz = model(first[0].cuda())\n",
    "print(zz.shape)\n",
    "print(first[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.utils.losses import DiceLoss\n",
    "from segmentation_models_pytorch.utils.base import Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dice_ce_loss(Loss):\n",
    "    def __init__(self, lambda_dice = 1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lambda_dice = lambda_dice\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # y_pred: (B, C, H, W)\n",
    "        # y_true: (B, C, H, W)\n",
    "\n",
    "        ce_loss = 0\n",
    "        dice_loss = monai.losses.DiceLoss(include_background = True, sigmoid=False, squared_pred=True, reduction='mean',\n",
    "            batch = True)\n",
    "        return dice_loss(y_pred, y_true) * self.lambda_dice + ce_loss * (1-self.lambda_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/kn2347/.conda/envs/medsam/lib/python3.10/site-packages/monai/losses/dice.py:153: UserWarning: single channel prediction, `include_background=False` ignored.\n",
      "  warnings.warn(\"single channel prediction, `include_background=False` ignored.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6771)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dice_test = dice_ce_loss(lambda_dice = 1)\n",
    "\n",
    "test_y_gt = torch.zeros((64, 1, 256, 256))\n",
    "test_y_gt[0, 0, 45, 45] = 1\n",
    "test_y_pred = torch.ones((64, 1, 256, 256)) * 0.001\n",
    "test_y_pred[0,0,45,45] = 1\n",
    "#loss.forward(test_y_pred, test_y_gt)\n",
    "loss_dice_test.forward(test_y_pred, test_y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = DiceLoss()\n",
    "loss = dice_ce_loss(lambda_dice = 1)\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=lr),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device='cuda',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device='cuda',\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train:   0%|          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 375/375 [1:54:58<00:00, 18.40s/it, dice_ce_loss - 0.267, iou_score - 0.6012]   \n",
      "valid: 100%|██████████| 47/47 [11:25<00:00, 14.59s/it, dice_ce_loss - 0.09295, iou_score - 0.832] \n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 375/375 [1:21:49<00:00, 13.09s/it, dice_ce_loss - 0.07109, iou_score - 0.8319]\n",
      "valid: 100%|██████████| 47/47 [09:04<00:00, 11.59s/it, dice_ce_loss - 0.085, iou_score - 0.8473]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 375/375 [1:17:18<00:00, 12.37s/it, dice_ce_loss - 0.0645, iou_score - 0.845]  \n",
      "valid: 100%|██████████| 47/47 [09:13<00:00, 11.78s/it, dice_ce_loss - 0.08195, iou_score - 0.8529]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|██████████| 375/375 [1:17:20<00:00, 12.37s/it, dice_ce_loss - 0.062, iou_score - 0.8501]  \n",
      "valid: 100%|██████████| 47/47 [08:36<00:00, 10.99s/it, dice_ce_loss - 0.08059, iou_score - 0.8559]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|██████████| 375/375 [1:41:34<00:00, 16.25s/it, dice_ce_loss - 0.06034, iou_score - 0.8536]\n",
      "valid: 100%|██████████| 47/47 [10:21<00:00, 13.23s/it, dice_ce_loss - 0.07962, iou_score - 0.8576]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|██████████| 375/375 [1:15:28<00:00, 12.08s/it, dice_ce_loss - 0.05915, iou_score - 0.8561]\n",
      "valid: 100%|██████████| 47/47 [07:51<00:00, 10.03s/it, dice_ce_loss - 0.07902, iou_score - 0.8589]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|██████████| 375/375 [1:08:56<00:00, 11.03s/it, dice_ce_loss - 0.05824, iou_score - 0.858] \n",
      "valid: 100%|██████████| 47/47 [07:44<00:00,  9.89s/it, dice_ce_loss - 0.07839, iou_score - 0.8602]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|██████████| 375/375 [1:06:47<00:00, 10.69s/it, dice_ce_loss - 0.05746, iou_score - 0.8596]\n",
      "valid: 100%|██████████| 47/47 [07:40<00:00,  9.81s/it, dice_ce_loss - 0.07804, iou_score - 0.8612]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|██████████| 375/375 [1:07:23<00:00, 10.78s/it, dice_ce_loss - 0.05669, iou_score - 0.8614]\n",
      "valid: 100%|██████████| 47/47 [07:50<00:00, 10.01s/it, dice_ce_loss - 0.07755, iou_score - 0.8622]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|██████████| 375/375 [1:07:57<00:00, 10.87s/it, dice_ce_loss - 0.05602, iou_score - 0.8628]\n",
      "valid: 100%|██████████| 47/47 [07:51<00:00, 10.02s/it, dice_ce_loss - 0.07733, iou_score - 0.8629]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 10\n",
      "train:  46%|████▌     | 172/375 [31:00<36:35, 10.81s/it, dice_ce_loss - 0.05508, iou_score - 0.8651] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m40\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m----> 6\u001b[0m     train_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     valid_logs \u001b[38;5;241m=\u001b[39m valid_epoch\u001b[38;5;241m.\u001b[39mrun(valid_loader)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# do something (save model, change lr, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/segmentation_models_pytorch/utils/train.py:49\u001b[0m, in \u001b[0;36mEpoch.run\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     41\u001b[0m metrics_meters \u001b[38;5;241m=\u001b[39m {metric\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m: AverageValueMeter() \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics}\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m     44\u001b[0m     dataloader,\n\u001b[1;32m     45\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_name,\n\u001b[1;32m     46\u001b[0m     file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout,\n\u001b[1;32m     47\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose),\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m iterator:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m     50\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     51\u001b[0m         loss, y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_update(x, y)\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/MedSAM/MedSAM_HCP/dataset.py:119\u001b[0m, in \u001b[0;36mMRIDataset_Imgs.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# load image as npy (256x256x3)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_frame\u001b[38;5;241m.\u001b[39mloc[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_slice_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     img_npy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/PIL/Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3234\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3236\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3238\u001b[0m preinit()\n\u001b[1;32m   3240\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "\n",
    "for i in range(0, 40):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, '/gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/test_label7_singletask_unet_testing_5-26-24/best_model.pth')\n",
    "        print('Model saved!')\n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate output metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_label1 = '/gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/unet_singletask_testing_5-26-24/best_model.pth'\n",
    "\n",
    "\n",
    "'''\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=num_classes,            # model output channels (number of classes in your dataset)\n",
    "    activation = activation\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(path_label1))\n",
    "model.eval()\n",
    "\n",
    "'''\n",
    "\n",
    "model = torch.load(path_label1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 42,  42,  42,  ..., 255, 255, 255]),\n",
       " tensor([141, 141, 142,  ..., 143, 143, 143]),\n",
       " tensor([139, 140, 133,  ..., 134, 135, 136]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(first[1][:,1,:,:] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15545abd1330>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "it = iter(test_loader)\n",
    "first = next(it)\n",
    "\n",
    "idx = 50\n",
    "imgo = first[0][idx:idx+1,:,:,:]\n",
    "seg = first[1][idx:idx+1,0,:,:]\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].imshow(np.squeeze(seg))\n",
    "\n",
    "print(imgo.shape)\n",
    "pred = model(imgo.cuda())[:,0,:,:]\n",
    "print(pred.shape)\n",
    "            \n",
    "axs[1].imshow(np.squeeze(pred.cpu().detach().numpy()))\n",
    "\n",
    "#zz = model(first[0])\n",
    "#print(zz.shape)\n",
    "#print(first[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
      "             ReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
      "             ReLU-17           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
      "             ReLU-26          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "             ReLU-30          [-1, 128, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "    ResNetEncoder-67  [[-1, 3, 256, 256], [-1, 64, 128, 128], [-1, 64, 64, 64], [-1, 128, 32, 32], [-1, 256, 16, 16], [-1, 512, 8, 8]]               0\n",
      "         Identity-68            [-1, 512, 8, 8]               0\n",
      "         Identity-69          [-1, 768, 16, 16]               0\n",
      "        Attention-70          [-1, 768, 16, 16]               0\n",
      "           Conv2d-71          [-1, 256, 16, 16]       1,769,472\n",
      "      BatchNorm2d-72          [-1, 256, 16, 16]             512\n",
      "             ReLU-73          [-1, 256, 16, 16]               0\n",
      "           Conv2d-74          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-75          [-1, 256, 16, 16]             512\n",
      "             ReLU-76          [-1, 256, 16, 16]               0\n",
      "         Identity-77          [-1, 256, 16, 16]               0\n",
      "        Attention-78          [-1, 256, 16, 16]               0\n",
      "     DecoderBlock-79          [-1, 256, 16, 16]               0\n",
      "         Identity-80          [-1, 384, 32, 32]               0\n",
      "        Attention-81          [-1, 384, 32, 32]               0\n",
      "           Conv2d-82          [-1, 128, 32, 32]         442,368\n",
      "      BatchNorm2d-83          [-1, 128, 32, 32]             256\n",
      "             ReLU-84          [-1, 128, 32, 32]               0\n",
      "           Conv2d-85          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-86          [-1, 128, 32, 32]             256\n",
      "             ReLU-87          [-1, 128, 32, 32]               0\n",
      "         Identity-88          [-1, 128, 32, 32]               0\n",
      "        Attention-89          [-1, 128, 32, 32]               0\n",
      "     DecoderBlock-90          [-1, 128, 32, 32]               0\n",
      "         Identity-91          [-1, 192, 64, 64]               0\n",
      "        Attention-92          [-1, 192, 64, 64]               0\n",
      "           Conv2d-93           [-1, 64, 64, 64]         110,592\n",
      "      BatchNorm2d-94           [-1, 64, 64, 64]             128\n",
      "             ReLU-95           [-1, 64, 64, 64]               0\n",
      "           Conv2d-96           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-97           [-1, 64, 64, 64]             128\n",
      "             ReLU-98           [-1, 64, 64, 64]               0\n",
      "         Identity-99           [-1, 64, 64, 64]               0\n",
      "       Attention-100           [-1, 64, 64, 64]               0\n",
      "    DecoderBlock-101           [-1, 64, 64, 64]               0\n",
      "        Identity-102        [-1, 128, 128, 128]               0\n",
      "       Attention-103        [-1, 128, 128, 128]               0\n",
      "          Conv2d-104         [-1, 32, 128, 128]          36,864\n",
      "     BatchNorm2d-105         [-1, 32, 128, 128]              64\n",
      "            ReLU-106         [-1, 32, 128, 128]               0\n",
      "          Conv2d-107         [-1, 32, 128, 128]           9,216\n",
      "     BatchNorm2d-108         [-1, 32, 128, 128]              64\n",
      "            ReLU-109         [-1, 32, 128, 128]               0\n",
      "        Identity-110         [-1, 32, 128, 128]               0\n",
      "       Attention-111         [-1, 32, 128, 128]               0\n",
      "    DecoderBlock-112         [-1, 32, 128, 128]               0\n",
      "          Conv2d-113         [-1, 16, 256, 256]           4,608\n",
      "     BatchNorm2d-114         [-1, 16, 256, 256]              32\n",
      "            ReLU-115         [-1, 16, 256, 256]               0\n",
      "          Conv2d-116         [-1, 16, 256, 256]           2,304\n",
      "     BatchNorm2d-117         [-1, 16, 256, 256]              32\n",
      "            ReLU-118         [-1, 16, 256, 256]               0\n",
      "        Identity-119         [-1, 16, 256, 256]               0\n",
      "       Attention-120         [-1, 16, 256, 256]               0\n",
      "    DecoderBlock-121         [-1, 16, 256, 256]               0\n",
      "     UnetDecoder-122         [-1, 16, 256, 256]               0\n",
      "          Conv2d-123          [-1, 1, 256, 256]             145\n",
      "        Identity-124          [-1, 1, 256, 256]               0\n",
      "         Sigmoid-125          [-1, 1, 256, 256]               0\n",
      "      Activation-126          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 14,328,209\n",
      "Trainable params: 3,151,697\n",
      "Non-trainable params: 11,176,512\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 284.75\n",
      "Params size (MB): 54.66\n",
      "Estimated Total Size (MB): 340.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 256, 256))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
