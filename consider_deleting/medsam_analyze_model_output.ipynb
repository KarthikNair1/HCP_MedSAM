{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "join = os.path.join\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import monai\n",
    "from monai.networks import one_hot\n",
    "from segment_anything import SamPredictor, sam_model_registry, build_sam_vit_b_multiclass\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "from utils.SurfaceDice import compute_dice_coefficient\n",
    "from skimage import io, transform\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "from torch.utils.data import RandomSampler\n",
    "import random\n",
    "import scipy\n",
    "import torch.nn.functional as F\n",
    "import img2pdf\n",
    "from torchmetrics import F1Score\n",
    "# set seeds\n",
    "torch.manual_seed(2023)\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset): \n",
    "    def __init__(self, data_frame, label_id, bbox_shift=0):\n",
    "        self.data_frame = data_frame\n",
    "        self.bbox_shift = bbox_shift\n",
    "        self.label_id = label_id\n",
    "        #print(f'number of images: {data_frame.shape[0]}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_frame.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # load image embedding as npy\n",
    "        img_embed_path = self.data_frame.loc[index,'image_embedding_slice_path']\n",
    "        img_embed_npy = np.load(img_embed_path) # (256, 64, 64)\n",
    "        img_slice_name = '_slice'.join(img_embed_path.split('/')[-2:])\n",
    "\n",
    "        # load segmentation mask as npy\n",
    "        seg_path = self.data_frame.loc[index,'segmentation_slice_path']\n",
    "        seg_npy = np.load(seg_path) # (256, 256)\n",
    "        seg_npy = (seg_npy==self.label_id).astype(np.uint8) # (256, 256)\n",
    "\n",
    "        assert np.max(seg_npy)<=1 and np.min(seg_npy)>=0, 'ground truth should be 0, 1'\n",
    "\n",
    "        # load bounding box coordinates from data frame\n",
    "        x_min, x_max = self.data_frame.loc[index, 'bbox_0'], self.data_frame.loc[index, 'bbox_2']\n",
    "        y_min, y_max = self.data_frame.loc[index, 'bbox_1'], self.data_frame.loc[index, 'bbox_3']\n",
    "        \n",
    "        # add perturbation to bounding box coordinates\n",
    "        H, W = seg_npy.shape\n",
    "        x_min = max(0, x_min - random.randint(0, self.bbox_shift))\n",
    "        x_max = min(W, x_max + random.randint(0, self.bbox_shift))\n",
    "        y_min = max(0, y_min - random.randint(0, self.bbox_shift))\n",
    "        y_max = min(H, y_max + random.randint(0, self.bbox_shift))\n",
    "        bboxes = np.array([x_min, y_min, x_max, y_max])\n",
    "        return torch.tensor(img_embed_npy).float(), torch.tensor(seg_npy[None, :, :]).long(), torch.tensor(bboxes).float(), img_slice_name\n",
    "    def load_image(self, index):\n",
    "        img_path = self.data_frame.loc[index, 'image_path']\n",
    "        slice_num = self.data_frame.loc[index, 'slice']\n",
    "        img = nib.load(img_path).get_fdata()[:,slice_num,:].astype(np.uint8)\n",
    "        return img # returns as (256, 256)\n",
    "\n",
    "\n",
    "# code to load train, val, test datasets\n",
    "def load_datasets(path_df_path, train_test_splits_path, label_id, bbox_shift=0, sample_n_slices = None):\n",
    "    # load dataframe of slice paths\n",
    "    path_df = pd.read_csv(path_df_path)\n",
    "\n",
    "    # load train val test ids\n",
    "    dicto = pickle.load(open(train_test_splits_path, 'rb'))\n",
    "    train_ids = dicto['train']\n",
    "    val_ids = dicto['val']\n",
    "    test_ids = dicto['test']\n",
    "\n",
    "    train_df = path_df[path_df['id'].isin(train_ids)].reset_index(drop=True)\n",
    "    val_df = path_df[path_df['id'].isin(val_ids)].reset_index(drop=True)\n",
    "    test_df = path_df[path_df['id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "    if sample_n_slices is not None:\n",
    "        train_df = train_df.sample(n=sample_n_slices, replace=False, random_state=2023).reset_index(drop=True)\n",
    "        val_df = val_df.sample(n=sample_n_slices, replace=False, random_state=2023).reset_index(drop=True)\n",
    "        test_df = test_df.sample(n=sample_n_slices, replace=False, random_state=2023).reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MRIDataset(train_df, label_id, bbox_shift)\n",
    "    val_dataset = MRIDataset(val_df, label_id, 0)\n",
    "    test_dataset = MRIDataset(test_df, label_id, 0)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "def medsam_inference(medsam_model, img_embed, box_1024, H, W):\n",
    "    box_torch = torch.as_tensor(box_1024, dtype=torch.float, device=img_embed.device)\n",
    "    if len(box_torch.shape) == 2:\n",
    "        box_torch = box_torch[:, None, :] # (B, 1, 4)\n",
    "    sparse_embeddings, dense_embeddings = medsam_model.prompt_encoder(\n",
    "        points=None,\n",
    "        boxes=box_torch,\n",
    "        masks=None,\n",
    "    )\n",
    "    low_res_logits, _ = medsam_model.mask_decoder(\n",
    "        image_embeddings=img_embed, # (B, 256, 64, 64)\n",
    "        image_pe=medsam_model.prompt_encoder.get_dense_pe(), # (1, 256, 64, 64)\n",
    "        sparse_prompt_embeddings=sparse_embeddings, # (B, 2, 256)\n",
    "        dense_prompt_embeddings=dense_embeddings, # (B, 256, 64, 64)\n",
    "        multimask_output=False,\n",
    "        )\n",
    "    \n",
    "    low_res_pred = torch.sigmoid(low_res_logits)  # (1, 1, 256, 256)\n",
    "\n",
    "    low_res_pred = F.interpolate(\n",
    "        low_res_pred,\n",
    "        size=(H, W),\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )  # (1, 1, gt.shape)\n",
    "    low_res_pred = low_res_pred.squeeze().cpu().detach().numpy()  # (256, 256)\n",
    "    medsam_seg = (low_res_pred > 0.5).astype(np.uint8)\n",
    "    return medsam_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_medsam_checkpt_to_readable_for_sam(checkpt, to_save_dir = None):\n",
    "    result = torch.load(checkpt)['model']\n",
    "\n",
    "    # now remove t{he \"module.\" prefix\n",
    "    result_dict = {}\n",
    "    for k,v in result.items():\n",
    "        new_k = '.'.join(k.split('.')[1:])\n",
    "        result_dict[new_k] = v\n",
    "    if to_save_dir is not None:\n",
    "        torch.save(result_dict, to_save_dir)\n",
    "    return result_dict\n",
    "\n",
    "def load_model(path, device = 'cuda'):\n",
    "    model = sam_model_registry['vit_b'](checkpoint=path)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization functions\n",
    "# source: https://github.com/facebookresearch/segment-anything/blob/main/notebooks/predictor_example.ipynb\n",
    "# change color to avoid red and green\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([251/255, 252/255, 30/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='blue', facecolor=(0,0,0,0), lw=2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this block to re-generate medsam checkpoints that are readable for the SAM module\n",
    "\n",
    "# path_1e4 = '/gpfs/home/kn2347/results/medsam_finetuning_model_checkpoints_7-18-23/MedSAM_finetune_hcp_ya_constant_bbox-20230721-230627/medsam_model_best.pth'\n",
    "# path_1e3 = '/gpfs/home/kn2347/results/medsam_finetuning_model_checkpoints_7-18-23/MedSAM_finetune_hcp_ya_constant_bbox-20230724-014522/medsam_model_best.pth'\n",
    "# path_1e5 = '/gpfs/home/kn2347/results/medsam_finetuning_model_checkpoints_7-18-23/MedSAM_finetune_hcp_ya_constant_bbox-20230721-133854/medsam_model_best.pth'\n",
    "# path_ori_medsam ='/gpfs/home/kn2347/MedSAM/medsam_vit_b.pth'\n",
    "# #_ = convert_medsam_checkpt_to_readable_for_sam(path_1e4, to_save_dir = '/gpfs/home/kn2347/results/medsam_evaluating_models_first_pass_7-22-23/model_1e-4_best.pth')\n",
    "# _ = convert_medsam_checkpt_to_readable_for_sam(path_1e3, to_save_dir = '/gpfs/home/kn2347/results/medsam_evaluating_models_first_pass_7-22-23/model_1e-3_best.pth')\n",
    "# _ = convert_medsam_checkpt_to_readable_for_sam(path_1e5, to_save_dir = '/gpfs/home/kn2347/results/medsam_evaluating_models_first_pass_7-22-23/model_1e-5_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df_path = '/gpfs/data/luilab/karthik/pediatric_seg_proj/path_df_constant_bbox.csv'\n",
    "train_test_splits_path = '/gpfs/data/luilab/karthik/pediatric_seg_proj/train_val_test_split.pickle'\n",
    "\n",
    "_, val_dataset, test_dataset = load_datasets(path_df_path, train_test_splits_path, label_id = 2, bbox_shift=0, sample_n_slices = None)\n",
    "\n",
    "path_1e4 = '/gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/medsam_evaluating_models_first_pass_7-22-23/model_1e-4_best.pth'\n",
    "path_1e3 = '/gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/medsam_evaluating_models_first_pass_7-22-23/model_1e-3_best.pth'\n",
    "path_1e5 = '/gpfs/data/luilab/karthik/pediatric_seg_proj/results_copied_from_kn2347/medsam_evaluating_models_first_pass_7-22-23/model_1e-5_best.pth'\n",
    "path_ori_medsam ='/gpfs/home/kn2347/MedSAM/medsam_vit_b.pth'\n",
    "device = 'cuda'\n",
    "\n",
    "medsam_model_1e3 = load_model(path_1e3, device)\n",
    "medsam_model_1e4 = load_model(path_1e4)\n",
    "medsam_model_1e5 = load_model(path_1e5)\n",
    "ori_sam_model = load_model(path_ori_medsam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef dice_score(truth, pred, eps=1e-7): # both have shape (B, C, 256, 256)\\n    N, C, sh1, sh2 = truth.size()   \\n    truth = truth.view(N,C,-1) # (N, C, sh1*sh2)\\n\\n    N, C, sh1, sh2 = pred.size()\\n    pred = pred.view(N, C, -1)\\n\\n    \\n\\n    dice_class_score=0\\n\\n    return dice_class_score\\n\\ndice_score(arr1, arr2, eps=1e-7)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_preprocess_slice(ds, img_idx, dev='cuda'):\n",
    "    image_data = ds.load_image(img_idx)\n",
    "    img_embedding, img_seg, img_box, slice_name = ds[img_idx]\n",
    "    img_embedding, img_seg, img_box = img_embedding.to(dev), img_seg.to(dev), img_box.to(dev)\n",
    "\n",
    "    # reshape for computation\n",
    "    img_embedding = img_embedding[None, :, :, :]\n",
    "    img_box = img_box.reshape((1,4))\n",
    "    img_box_1024 = img_box * 4 # for ori model\n",
    "    img_seg = img_seg.cpu().numpy()\n",
    "\n",
    "    return image_data, img_embedding, img_box, img_box_1024, img_seg\n",
    "def is_slice_blank(image_data):\n",
    "    return np.abs(image_data).sum() == 0\n",
    "def seg_get_class_indices(preds): # preds should be of shape (B, H, W) or (B, C, H, W)\n",
    "    if not torch.is_tensor(preds):\n",
    "        preds = torch.IntTensor(preds)\n",
    "    assert not torch.is_floating_point(preds)  # must be class numbers\n",
    "\n",
    "    if len(preds.shape) == 3:\n",
    "        # this is 0's and 1's already, so good as is\n",
    "        return preds[:, None, :, :]\n",
    "    elif len(preds.shape) == 4:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def dice_score_single_class(truth, pred, eps=1e-7):\n",
    "    # B, 1, Rows, Columns for both truth and pred\n",
    "    # values are 0 or 1: calculate overlap w.r.t. the 1\n",
    "    B, classes, r, c = truth.size()\n",
    "    assert classes == 1\n",
    "    truth = truth.view(B, -1).cuda()\n",
    "    pred = pred.view(B, -1).cuda()\n",
    "\n",
    "    overlap_term = (truth * pred).sum(dim=1) * 2 + eps\n",
    "    union_term = (truth + pred).sum(dim=1) + eps\n",
    "\n",
    "\n",
    "    return (overlap_term / union_term).mean().cpu().item()\n",
    "\n",
    "'''\n",
    "def dice_score(truth, pred, eps=1e-7): # both have shape (B, C, 256, 256)\n",
    "    N, C, sh1, sh2 = truth.size()   \n",
    "    truth = truth.view(N,C,-1) # (N, C, sh1*sh2)\n",
    "\n",
    "    N, C, sh1, sh2 = pred.size()\n",
    "    pred = pred.view(N, C, -1)\n",
    "\n",
    "    \n",
    "\n",
    "    dice_class_score=0\n",
    "\n",
    "    return dice_class_score\n",
    "\n",
    "dice_score(arr1, arr2, eps=1e-7)\n",
    "'''\n",
    "#dice_score_single_class(arr1, arr2, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/888 [00:05<16:50,  1.14s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 37\u001b[0m\n\u001b[1;32m     32\u001b[0m             list_slice_nums\u001b[39m.\u001b[39mappend(\u001b[39mint\u001b[39m(slice_names[i]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m stats_lists\n\u001b[0;32m---> 37\u001b[0m stats_list \u001b[39m=\u001b[39m run_model_on_dataset(medsam_model_1e4, val_dataset)\n",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m, in \u001b[0;36mrun_model_on_dataset\u001b[0;34m(model, test_ds, dest_H, dest_W, output_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m list_slice_nums \u001b[39m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m stats_lists \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdice_score_with_ground_truth\u001b[39m\u001b[39m'\u001b[39m:[]}\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m step, (image_embedding, gt2D, boxes, slice_names) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(dataloader)):\n\u001b[1;32m     16\u001b[0m     image_embedding, gt2D, boxes \u001b[39m=\u001b[39m image_embedding\u001b[39m.\u001b[39mcuda(), gt2D\u001b[39m.\u001b[39mcuda(), boxes\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     17\u001b[0m     medsam_pred \u001b[39m=\u001b[39m medsam_inference(model, image_embedding, boxes, dest_H, dest_W) \u001b[39m# numpy (B, 256, 256)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_model_on_dataset(model, test_ds, dest_H=256, dest_W=256, output_path = ''):\n",
    "    # output should be pandas dataframe with paths to segmentations, as well as summary stats (e.g. dice scores w.r.t. ground truth)\n",
    "    dataloader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size = 32,\n",
    "        shuffle = False,\n",
    "        num_workers = 1,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    list_ids = []\n",
    "    list_slice_nums = []\n",
    "    stats_lists = {'dice_score_with_ground_truth':[]}\n",
    "\n",
    "    for step, (image_embedding, gt2D, boxes, slice_names) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        image_embedding, gt2D, boxes = image_embedding.cuda(), gt2D.cuda(), boxes.cuda()\n",
    "        medsam_pred = medsam_inference(model, image_embedding, boxes, dest_H, dest_W) # numpy (B, 256, 256)\n",
    "        \n",
    "        #print(medsam_pred.shape) # np arrqay of size (B, 256, 256), later generalize to (batches, classes, 256, 256)\n",
    "        #print(gt2D.shape) # tensor of size (B, 1, 256, 256)\n",
    "        \n",
    "        medsam_pred = seg_get_class_indices(medsam_pred) # now (batches, classes, 256, 256)\n",
    "        \n",
    "        # generate stats here\n",
    "        dice_score = dice_score_single_class(gt2D, medsam_pred, eps=1e-6)\n",
    "        \n",
    "        stats_lists['dice_score_with_ground_truth'].append(dice_score)\n",
    "        # backmap using id's and slice nums\n",
    "        # slice_names: list of B values formatted as '{id}_slice{slice_num}.npy'\n",
    "        for i in range(len(slice_names)):\n",
    "            list_ids.append(int(slice_names[i].split('_')[0]))\n",
    "            list_slice_nums.append(int(slice_names[i].split('_')[1].split('.npy')[0].split('slice')[1]))\n",
    "        \n",
    "    return stats_lists\n",
    "    \n",
    "\n",
    "stats_list = run_model_on_dataset(medsam_model_1e4, val_dataset)\n",
    "#print(sum(stats_list['dice_score_with_ground_truth']) / len(stats_list['dice_score_with_ground_truth']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_example(test_ds, model_list, names_list, dev='cuda', dest_H=256, dest_W=256, n_ex = 1, seed=182, restrict_to_label_present = True):\n",
    "    np.random.seed(seed)\n",
    "    # set up the plot\n",
    "    fig, axs = plt.subplots(n_ex, len(model_list)+2, figsize=(25, 25)) # 0 index is ground truth segmentation\n",
    "    \n",
    "    for iter in range(n_ex):\n",
    "        print(iter)\n",
    "        while True:\n",
    "            img_idx = np.random.randint(len(test_ds))\n",
    "\n",
    "            # load image, embedding, segmentation, and input mask\n",
    "            image_data, img_embedding, img_box, img_box_1024, img_seg = load_and_preprocess_slice(test_ds, img_idx, dev)\n",
    "\n",
    "            # break if blank\n",
    "            if is_slice_blank(image_data):\n",
    "                continue\n",
    "            \n",
    "            seg_list = []\n",
    "\n",
    "            # run inference\n",
    "            for model in model_list:\n",
    "                this_seg_result = medsam_inference(model, img_embedding, img_box, H=dest_H, W=dest_W) #(dest_H,dest_W)\n",
    "                seg_list.append(this_seg_result)\n",
    "\n",
    "            segmentation_mask_sum = sum([x.sum() for x in seg_list])\n",
    "            total_sum = img_seg.sum() + segmentation_mask_sum\n",
    "            if total_sum == 0: # neither ground truth nor segmentations have any predicted True's\n",
    "                continue\n",
    "\n",
    "            break\n",
    "            \n",
    "        # plot \n",
    "        \n",
    "        image_data_3c = np.repeat(image_data[:,:,None], 3, axis=-1)\n",
    "\n",
    "        axs[iter, 0].imshow(image_data_3c)\n",
    "        if iter == 0:\n",
    "            axs[iter, 0].set_title('Input Image', fontsize=20)\n",
    "        axs[iter, 0].axis('off')\n",
    "\n",
    "        axs[iter, 1].imshow(image_data_3c)\n",
    "        show_mask(img_seg>0, axs[iter, 1])\n",
    "        if iter == 0:\n",
    "            axs[iter, 1].set_title('Ground Truth', fontsize=20)\n",
    "        axs[iter, 1].axis('off')\n",
    "\n",
    "        for i in range(len(model_list)):\n",
    "            axs[iter, i+2].imshow(image_data_3c)\n",
    "            show_mask(seg_list[i], axs[iter, i+2])\n",
    "            show_box(img_box.flatten().cpu().numpy(), axs[iter, i+2])\n",
    "            if iter==0:\n",
    "                axs[iter, i+2].set_title(f'{names_list[i]} Segmentation', fontsize=20)\n",
    "            axs[iter, i+2].axis('off')\n",
    "\n",
    "    fig.show()\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "    return fig, axs, seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/gpfs/home/kn2347/results/medsam_finetuning_outputs_7-24_23'\n",
    "for iter_idx in range(100):\n",
    "    fig, axs, seg_list = plot_random_example(test_dataset, [medsam_model_1e3, medsam_model_1e4, medsam_model_1e5], ['lr=1e-3', 'lr=1e-4', 'lr=1e-5'], dev='cuda', dest_H=256, dest_W=256, n_ex=5, restrict_to_label_present=True, seed = iter_idx)\n",
    "    fig.savefig(os.path.join(save_path, f'plot_{iter_idx}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n",
      "Image contains an alpha channel. Computing a separate soft mask (/SMask) image to store transparency in PDF.\n"
     ]
    }
   ],
   "source": [
    "rt = \"/gpfs/home/kn2347/results/medsam_finetuning_outputs_7-24_23\"\n",
    "with open(\"/gpfs/home/kn2347/results/medsam_finetuning_outputs_7-24_23/results_model_output_7-24-23.pdf\", 'wb') as f:\n",
    "    list_paths = [f'{rt}/plot_{x}.png'for x in range(100)]\n",
    "    f.write(img2pdf.convert(list_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly iterate over the dataset\n",
    "num_iters = 10\n",
    "for i in range(num_iters):\n",
    "    # pick random example\n",
    "    img_idx = np.random.randint(len(test_dataset))\n",
    "\n",
    "    # load image, embedding, segmentation, and input mask\n",
    "    image_data = test_dataset.load_image(img_idx)\n",
    "    img_embedding, img_seg, img_box, slice_name = test_dataset[img_idx]\n",
    "    img_embedding, img_seg, img_box = img_embedding.to(device), img_seg.to(device), img_box.to(device)\n",
    "\n",
    "    # reshape for computation\n",
    "    img_embedding = img_embedding[None, :, :, :]\n",
    "    img_box = img_box.reshape((1,4))\n",
    "    img_box_1024 = img_box * 4\n",
    "    img_seg = img_seg.cpu().numpy()\n",
    "\n",
    "    # run inference\n",
    "    seg_result = medsam_inference(medsam_model_1e4, img_embedding, img_box, H=256, W=256)\n",
    "    seg_result_ori_sam = medsam_inference(ori_sam_model, img_embedding, img_box_1024, H=256, W=256)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (196608,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m _, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m25\u001b[39m, \u001b[39m25\u001b[39m))\n\u001b[1;32m     23\u001b[0m image_data_3c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(image_data[:,:,\u001b[39mNone\u001b[39;00m], \u001b[39m3\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m axs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mimshow(image_data_3c)\n\u001b[1;32m     26\u001b[0m axs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mset_title(\u001b[39m'\u001b[39m\u001b[39mInput Image\u001b[39m\u001b[39m'\u001b[39m, fontsize\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m     27\u001b[0m axs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5665\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5658\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[1;32m   5659\u001b[0m                       interpolation\u001b[39m=\u001b[39minterpolation, origin\u001b[39m=\u001b[39morigin,\n\u001b[1;32m   5660\u001b[0m                       extent\u001b[39m=\u001b[39mextent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[1;32m   5661\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[1;32m   5662\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5663\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5665\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5666\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5667\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5668\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/medsam/lib/python3.10/site-packages/matplotlib/image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    711\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    714\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    715\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (196608,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x2500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axs = plt.subplots(1, 3, figsize=(25, 25))\n",
    "\n",
    "image_data_3c = np.repeat(image_data[:,:,None], 3, axis=-1)\n",
    "\n",
    "axs[0].imshow(image_data_3c)\n",
    "axs[0].set_title('Input Image', fontsize=20)\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(image_data_3c)\n",
    "show_mask(img_seg>0, axs[1])\n",
    "axs[1].set_title('Ground Truth', fontsize=20)\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(image_data_3c)\n",
    "show_mask(seg_result, axs[2])\n",
    "show_box(img_box.flatten().cpu().numpy(), axs[2])\n",
    "axs[2].set_title('MedSAM Segmentation', fontsize=20)\n",
    "axs[2].axis('off')\n",
    "plt.show()  \n",
    "plt.subplots_adjust(wspace=0.01, hspace=0)\n",
    "\n",
    "# save plot\n",
    "# plt.savefig(join(model_save_path, test_npzs[npz_idx].split('.npz')[0] + str(img_id).zfill(3) + '.png'), bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
